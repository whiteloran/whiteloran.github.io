<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"whiteloran.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Il n&#39;ya qu&#39;un héroïsme au monde, c&#39;est de voir le monde tel qu&#39;il est et de l&#39;aimer.">
<meta property="og:type" content="website">
<meta property="og:title" content="Whiteloran&#39;s Blog">
<meta property="og:url" content="http://whiteloran.github.io/Paper/index.html">
<meta property="og:site_name" content="Whiteloran&#39;s Blog">
<meta property="og:description" content="Il n&#39;ya qu&#39;un héroïsme au monde, c&#39;est de voir le monde tel qu&#39;il est et de l&#39;aimer.">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="whiteloran">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://whiteloran.github.io/Paper/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Category:  | Whiteloran's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Whiteloran's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">For Further Future</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-index">

    <a href="/indexer/" rel="section"><i class="fa fa-list fa-fw"></i>Index</a>

  </li>
        
            
  <li class="menu-item menu-item-files">

    <a href="/Files/" rel="section"><i class="fa fa-file fa-fw"></i>Files</a>

  </li>


      
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-cube fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Timeline</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/yourname" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content page post">
            

  <div class="post-block">  
    <h2>PapeRead</h2>   
  </div>
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/04/01/22040101/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/01/22040101/" class="post-title-link" itemprop="url">论文略读2022-04-01</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-01 20:00:00" itemprop="dateCreated datePublished" datetime="2022-04-01T20:00:00+08:00">2022-04-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Heterogeneous-Graph-Attention-Network-for-Unsupervised-Multiple-Target-Domain-Adaptation"><a href="#Heterogeneous-Graph-Attention-Network-for-Unsupervised-Multiple-Target-Domain-Adaptation" class="headerlink" title="Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation"></a>Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation</h3><p>上线时间：2020-09-23<br>期刊：IEEE TPAMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9204804">https://ieeexplore.ieee.org/document/9204804</a></p>
<p>工程意义：多目标域<br>工程创新：异构图注意力网络，学习域无关空间。<br>方法：通过异构图注意力网络学习所有域通用的统一子空间，其中图注意力网络的转导能力可以在多个域之间进行相关样本的语义传播。注意力机制被应用于优化多个领域样本的关系，以实现更好的语义转移。然后，利用图注意力网络预测的目标域的伪标签，通过对齐标记的源域和伪标记的目标域来学习域不变表示。</p>
<p>开源：否<br>评论：一直以来，使用图网络理论上会获得比传统深度网络更好的逻辑和方法，但在深度学习方法已经能做到disentanglement的情况下，这里用图网络来学domain invariant的内容，就显得在方法上写的不够先进。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202204011444959.png" width="80%"/>

<h3 id="Generalizable-Cross-modality-Medical-Image-Segmentation-via-Style-Augmentation-and-Dual-Normalization"><a href="#Generalizable-Cross-modality-Medical-Image-Segmentation-via-Style-Augmentation-and-Dual-Normalization" class="headerlink" title="Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization"></a>Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization</h3><p>上线时间：2021-12-21<br>期刊：CVPR 2022<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.11177">https://arxiv.org/abs/2112.11177</a></p>
<p>临床意义：更少的数据和标签需求<br>工程创新：从UDA到DG，应用风格增强+双路归一化。<br>方法：首先利用非线性变换来增强源相似和源不同的图像。共享主干网络，在归一化层进行单独归一化。之后，使用基于样式的选择方案，在测试阶段自动选择合适的数据路径。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/zzzqzhou/Dual-Normalization">https://github.com/zzzqzhou/Dual-Normalization</a><br>评论：一直以来很多工作都在试图用DG来代替UDA，但在公开数据上，DG常常结果一般。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202204011505495.png"/>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/03/30/22033001/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/30/22033001/" class="post-title-link" itemprop="url">论文略读2022-03-30</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-30 20:00:00" itemprop="dateCreated datePublished" datetime="2022-03-30T20:00:00+08:00">2022-03-30</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="FReSCO-Flow-Reconstruction-and-Segmentation-for-low-latency-Cardiac-Output-monitoring-using-deep-artifact-suppression-and-segmentation"><a href="#FReSCO-Flow-Reconstruction-and-Segmentation-for-low-latency-Cardiac-Output-monitoring-using-deep-artifact-suppression-and-segmentation" class="headerlink" title="FReSCO: Flow Reconstruction and Segmentation for low latency Cardiac Output monitoring using deep artifact suppression and segmentation"></a>FReSCO: Flow Reconstruction and Segmentation for low latency Cardiac Output monitoring using deep artifact suppression and segmentation</h3><p>上线时间：2022-03-25<br>期刊：N/A<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.13729">https://arxiv.org/abs/2203.13729</a></p>
<p>临床意义：心输出量 (CO) 的实时监测需要实时相位对比 MR (PCMR) 的低延迟重建和分割。<br>工程创新：独立训练深度伪影抑制和分割 U-Net。<br>方法：独立训练深度伪影抑制和分割 U-Net。</p>
<p>开源：否<br>评论：临床意义还算可以，工程部分挺一般的。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203301414363.png" width="80%" />


<h3 id="Student-Become-Decathlon-Master-in-Retinal-Vessel-Segmentation-via-Dual-teacher-Multi-target-Domain-Adaptation"><a href="#Student-Become-Decathlon-Master-in-Retinal-Vessel-Segmentation-via-Dual-teacher-Multi-target-Domain-Adaptation" class="headerlink" title="Student Become Decathlon Master in Retinal Vessel Segmentation via Dual-teacher Multi-target Domain Adaptation"></a>Student Become Decathlon Master in Retinal Vessel Segmentation via Dual-teacher Multi-target Domain Adaptation</h3><p>上线时间：2022-03-07<br>期刊：N/A<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.03631">https://arxiv.org/abs/2203.03631</a></p>
<p>工程意义：多目标域适应。<br>工程创新：双重知识蒸馏<br>方法：风格增强和迁移（SAT）模块和双师知识蒸馏（DTKD）模块组成。SAT 通过贝塞尔和傅里叶变换将图像增强和聚类到源相似域和源不同域。DTKD 利用增强和转换的数据来训练两名教师，一个用于源相似域，另一个用于源不同域。之后，进行知识蒸馏，以迭代地将不同的领域知识从教师提炼到学生。</p>
<p>开源：暂未；<a target="_blank" rel="noopener" href="https://github.com/lkpengcs/rvms">https://github.com/lkpengcs/rvms</a><br>评论：双重蒸馏已经挺常见的了，感觉创新性不是很足。变换法进行域转移的话，FedDG在好久前就有做过类似的。此外，视网膜图像在不同的中心条件下是相似的，或许这种UDA的效果不会很in the wild。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203302111692.png" width="80%"/>

<h3 id="Multi-Source-Unsupervised-Domain-Adaptation-via-Pseudo-Target-Domain"><a href="#Multi-Source-Unsupervised-Domain-Adaptation-via-Pseudo-Target-Domain" class="headerlink" title="Multi-Source Unsupervised Domain Adaptation via Pseudo Target Domain"></a>Multi-Source Unsupervised Domain Adaptation via Pseudo Target Domain</h3><p>上线时间：2022-02-23<br>期刊：IEEE TIP<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9720154">https://ieeexplore.ieee.org/document/9720154</a></p>
<p>工程意义：多源域适应<br>工程创新：构建伪目标域<br>方法：使用具有度量约束的对抗学习将每组源域和目标域映射到一个特定于组的子空间，并相应地构造一系列伪目标域。然后，将剩余源域与子空间中的伪目标域对齐，这允许通过对伪目标域的训练来利用额外的结构化源信息，并提高真实目标域的性能。</p>
<p>开源：否<br>评论：多源域适应是一个常见的问题，这个解法还行。此外，网络图画的不是很好看懂，因为没有主体。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203302144316.png" width="80%"/>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/03/29/22032901/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/29/22032901/" class="post-title-link" itemprop="url">论文略读2022-03-29</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-29 20:00:00" itemprop="dateCreated datePublished" datetime="2022-03-29T20:00:00+08:00">2022-03-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="On-the-Fly-Test-time-Adaptation-for-Medical-Image-Segmentation"><a href="#On-the-Fly-Test-time-Adaptation-for-Medical-Image-Segmentation" class="headerlink" title="On-the-Fly Test-time Adaptation for Medical Image Segmentation"></a>On-the-Fly Test-time Adaptation for Medical Image Segmentation</h3><p>上线时间：2022-03-10<br>期刊：N/A<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.05574">https://arxiv.org/abs/2203.05574</a></p>
<p>临床意义：高速域适应：在现实世界的临床环境中，动态调整模型以适应新的测试图像并避免在推理过程中由于隐私问题和部署时缺乏计算资源而更新模型更有意义。<br>工程创新：zero-shot + episodic<br>方法：对Unet的每个卷积块都配备了一个自适应批量归一化层，以根据pre-train的域代码调整特征。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/jeya-maria-jose/On-The-Fly-Adaptation">https://github.com/jeya-maria-jose/On-The-Fly-Adaptation</a><br>评论：看到开头以为挺好，往后看了感觉一般。实验做得有点问题。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203292110070.png" width="80%" />

<blockquote>
<p>episodic (i.e., the model is adapted to a single image at a time and also does not perform any back-propagation during test-time)</p>
</blockquote>
<h3 id="Identifying-and-preventing-cardiovascular-disease-in-patients-with-cystic-fibrosis"><a href="#Identifying-and-preventing-cardiovascular-disease-in-patients-with-cystic-fibrosis" class="headerlink" title="Identifying and preventing cardiovascular disease in patients with cystic fibrosis"></a>Identifying and preventing cardiovascular disease in patients with cystic fibrosis</h3><p>上线时间：2022-03-10<br>期刊：Nature CVR<br>链接：<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s44161-022-00030-y">https://www.nature.com/articles/s44161-022-00030-y</a></p>
<p>临床声明：提高护理标准和新疗法意味着囊性纤维化患者的寿命更长，但这会增加患非传染性疾病的风险，尤其是心血管疾病 (CVD)。为了提高寿命和生活质量，重要的是要考虑囊性纤维化患者的 CVD 风险和预防措施。</p>
<p>评论：一篇comment。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203292153743.png"/>


<h3 id="Active-Learning-for-Domain-Adaptation-An-Energy-Based-Approach"><a href="#Active-Learning-for-Domain-Adaptation-An-Energy-Based-Approach" class="headerlink" title="Active Learning for Domain Adaptation: An Energy-Based Approach"></a>Active Learning for Domain Adaptation: An Energy-Based Approach</h3><p>上线时间：2021-12-02<br>期刊：AAAI 2022<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.01406">https://arxiv.org/abs/2112.01406</a></p>
<p>工程意义：提出了一种新的主​​动学习策略来帮助目标域中的知识转移，称为主动域适应。<br>工程创新：当训练（源）和测试（目标）数据来自不同分布时，基于能量的模型表现出自由能偏差，基于能量的采样策略有助于选择最有价值的目标样本。<br>方法：查询目标数据组，在每一轮选择中纳入领域特征和实例的不确定性。同时，通过正则化项对齐目标数据的自由能与源域周围的自由能，隐性地缩小域之间的差距。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/BIT-DA/EADA">https://github.com/BIT-DA/EADA</a><br>评论：基于能量模型的UDA还是比较少见到的。或许我可以再看一下。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203292214878.png" width="80%"/>


<h3 id="Dual-Modality-Volume-Measurement-Integrated-on-a-Ventricular-Assist-Device"><a href="#Dual-Modality-Volume-Measurement-Integrated-on-a-Ventricular-Assist-Device" class="headerlink" title="Dual-Modality Volume Measurement Integrated on a Ventricular Assist Device"></a>Dual-Modality Volume Measurement Integrated on a Ventricular Assist Device</h3><p>上线时间：2021-09-24<br>期刊：IEEE TBME<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9547820">https://ieeexplore.ieee.org/document/9547820</a></p>
<p>临床挑战：使用一种传感器模式的体积测量需要在 VAD 植入后的特定时间重新校准。<br>工程创新：将超声和阻抗体积测量技术集成到心尖 VAD 中。</p>
<p>评论：硬件上的多模态测量。实验较为简单。</p>
<h3 id="Zero-Shot-Video-Object-Segmentation-With-Co-Attention-Siamese-Networks"><a href="#Zero-Shot-Video-Object-Segmentation-With-Co-Attention-Siamese-Networks" class="headerlink" title="Zero-Shot Video Object Segmentation With Co-Attention Siamese Networks"></a>Zero-Shot Video Object Segmentation With Co-Attention Siamese Networks</h3><p>上线时间：2020-11-24<br>期刊：IEEE TPAMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9268466">https://ieeexplore.ieee.org/document/9268466</a></p>
<p>工程挑战：Zero-Shot<br>工程创新：差异化的共同注意力机制<br>方法：利用视频帧之间的内在相关性并结合全局共同注意力机制，学习短期时间段中外观和运动的判别前景表示。</p>
<p>评论：确切来说，这个方法没有进行对于时序的建模，有点类似Trans对LSTM的改变一样，这个网络抽取视频序列中的任意两帧输入网络，并建模帧和帧的关系。这样它能学到的关系其实是更丰富的。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203292222357.png" width="80%"/>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/03/28/22032801/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/28/22032801/" class="post-title-link" itemprop="url">论文略读2022-03-28</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-28 20:00:00" itemprop="dateCreated datePublished" datetime="2022-03-28T20:00:00+08:00">2022-03-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="CrossMoDA-2021-challenge-Benchmark-of-Cross-Modality-Domain-Adaptation-techniques-for-Vestibular-Schwannoma-and-Cochlea-Segmentation"><a href="#CrossMoDA-2021-challenge-Benchmark-of-Cross-Modality-Domain-Adaptation-techniques-for-Vestibular-Schwannoma-and-Cochlea-Segmentation" class="headerlink" title="CrossMoDA 2021 challenge: Benchmark of Cross-Modality Domain Adaptation techniques for Vestibular Schwannoma and Cochlea Segmentation"></a>CrossMoDA 2021 challenge: Benchmark of Cross-Modality Domain Adaptation techniques for Vestibular Schwannoma and Cochlea Segmentation</h3><p>上线时间：2022-01-08<br>期刊：MIA</p>
<p>开源：<a target="_blank" rel="noopener" href="https://paperswithcode.com/dataset/crossmoda">https://paperswithcode.com/dataset/crossmoda</a></p>
<p>评论：公开的脑部跨模态域适应数据集。</p>
<h3 id="MT-UDA-Towards-Unsupervised-Cross-modality-Medical-Image-Segmentation-with-Limited-Source-Labels"><a href="#MT-UDA-Towards-Unsupervised-Cross-modality-Medical-Image-Segmentation-with-Limited-Source-Labels" class="headerlink" title="MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels"></a>MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels</h3><p>上线时间：2021-09-21<br>期刊：MICCAI<br>链接：<a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-87193-2_28">https://link.springer.com/chapter/10.1007/978-3-030-87193-2_28</a></p>
<p>临床意义：通用意义，标签稀缺。<br>工程创新：A+B: Unsupervised DA + Knowledge Transfer<br>方法：双重师生模型+UDA</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/jacobzhaoziyuan/MT-UDA">https://github.com/jacobzhaoziyuan/MT-UDA</a><br>评论：源域半监督+跨域UDA+双重师生模型。叠起来还是挺好的。双循环对位模块用于双向降低域漂移，生成近似源域和近似目标域。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281546360.png" width="80%">

<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281559651.png" width="80%">

<h3 id="Semi-Supervised-Hybrid-Spine-Network-for-Segmentation-of-Spine-MR-Images"><a href="#Semi-Supervised-Hybrid-Spine-Network-for-Segmentation-of-Spine-MR-Images" class="headerlink" title="Semi-Supervised Hybrid Spine Network for Segmentation of Spine MR Images"></a>Semi-Supervised Hybrid Spine Network for Segmentation of Spine MR Images</h3><p>上线时间：2021-09-21<br>期刊：N/A<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.12151">https://arxiv.org/abs/2203.12151</a></p>
<p>临床意义：在3DMRI中，自动分割椎体 (VB) 和椎间盘 (IVD) 对于诊断和治疗脊柱疾病很重要。<br>工程创新：混合半监督+注意力机制<br>方法：2D+3D Deeplab + 三重注意力融合</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/meiyan88/sshsnet">https://github.com/meiyan88/sshsnet</a></p>
<p>评论：用较长的篇幅解释清楚了怎么完成网络构建。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281602693.png" width="80%">

<h3 id="JCS-An-Explainable-COVID-19-Diagnosis-System-by-Joint-Classification-and-Segmentation"><a href="#JCS-An-Explainable-COVID-19-Diagnosis-System-by-Joint-Classification-and-Segmentation" class="headerlink" title="JCS: An Explainable COVID-19 Diagnosis System by Joint Classification and Segmentation"></a>JCS: An Explainable COVID-19 Diagnosis System by Joint Classification and Segmentation</h3><p>上线时间：2021-02-18（投稿2020-03-16）<br>期刊：IEEE TIP<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9357961/">https://ieeexplore.ieee.org/abstract/document/9357961/</a></p>
<p>临床意义：胸部CT扫描测试为RT-PCR测试提供补充信息，用于感染检查。<br>工程创新：联合分类和分割 (JCS) 系统来执行实时和可解释的 COVID-19 胸部 CT 诊断。<br>方法：双路网络。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/yuhuan-wu/JCS">https://github.com/yuhuan-wu/JCS</a><br>评论：写得快，数据集大加上有现实实践真的可以随便做的。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281613364.png" width="80%">

<h3 id="Disentangled-Inference-for-GANs-With-Latently-Invertible-Autoencoder"><a href="#Disentangled-Inference-for-GANs-With-Latently-Invertible-Autoencoder" class="headerlink" title="Disentangled Inference for GANs With Latently Invertible Autoencoder"></a>Disentangled Inference for GANs With Latently Invertible Autoencoder</h3><p>上线时间：2022-03-22（投稿2020-03-16）<br>期刊：IJCV 2022<br>链接：<a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s11263-022-01598-5">https://link.springer.com/article/10.1007/s11263-022-01598-5</a></p>
<p>工程挑战：生成对抗网络 (GAN) 无法在潜在空间中编码真实样本。we cannot infer the latent variable $z$ corresponding to a given sample $x$ such that the image can be faithfully reconstructed from $z$ by the GAN generator.<br>方法：潜在可逆自动编码器 (LIA) 。在 LIA 中，可逆网络及其逆映射对称地嵌入自编码器的潜在空间中。LIA 的解码器首先被训练为具有可逆网络的标准 GAN，然后通过将可逆网络从 LIA 中分离出来，从解纠缠的自动编码器中学习编码器。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/genforce/lia">https://github.com/genforce/lia</a><br>评论：对潜在空间的解纠缠的解析使用了VAE来完成，可以视作用VAE来外联GAN。能够对潜在空间解纠缠可以让GAN的生成的定向能力提升。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281624952.png" width="80%">

<h3 id="CDTrans-Cross-domain-Transformer-for-Unsupervised-Domain-Adaptation"><a href="#CDTrans-Cross-domain-Transformer-for-Unsupervised-Domain-Adaptation" class="headerlink" title="CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation"></a>CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation</h3><p>上线时间：2021-09-13<br>期刊：ICCV 2021<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2109.06165">https://arxiv.org/abs/2109.06165</a></p>
<p>工程挑战：基于类别级别的 UDA 的一个基本问题是为目标域中的样本生成伪标签，这些伪标签通常对于准确的域对齐来说过于嘈杂，不可避免地会影响 UDA 的性能。<br>工程创新：Transformer 中的交叉注意力对嘈杂的输入对具有鲁棒性，可以更好地进行特征对齐。<br>方法：设计了一种双向中心感知标签算法来为目标样本生成伪标签。除了伪标签之外，还提出了一个权重共享的三分支转换器框架，以分别将自注意力和交叉注意力应用于源/目标特征学习和源-目标域对齐。</p>
<p>开源：<a target="_blank" rel="noopener" href="https://github.com/cdtrans/cdtrans">https://github.com/cdtrans/cdtrans</a><br>评论：构造Transformer来完成UDA，降低伪标签的噪声影响。实验做得一般。</p>
<img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281703324.png" width="80%">
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/03/23/22032301/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/23/22032301/" class="post-title-link" itemprop="url">论文略读2022-03-23</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-23 20:00:00" itemprop="dateCreated datePublished" datetime="2022-03-23T20:00:00+08:00">2022-03-23</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Domain-Adaptation-Meets-Zero-Shot-Learning-An-Annotation-Efficient-Approach-to-Multi-Modality-Medical-Image-Segmentation"><a href="#Domain-Adaptation-Meets-Zero-Shot-Learning-An-Annotation-Efficient-Approach-to-Multi-Modality-Medical-Image-Segmentation" class="headerlink" title="Domain Adaptation Meets Zero-Shot Learning: An Annotation-Efficient Approach to Multi-Modality Medical Image Segmentation"></a>Domain Adaptation Meets Zero-Shot Learning: An Annotation-Efficient Approach to Multi-Modality Medical Image Segmentation</h3><p>上线时间：2021-11-29<br>期刊：IEEE TMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9627926">https://ieeexplore.ieee.org/abstract/document/9627926</a></p>
<p>临床意义：通用意义，标签稀缺（UDA）。数据安全（ZSL）。<br>工程创新：A+B: Unsupervised DA + Zero-Shot L<br>方法：先验模型+适应模型</p>
<p>开源：否<br>评论：用ZSL来只利用从Source Domain学习到的模型，而不需要涉及到Source Domain所使用到的图像。这样避免了UDA在训练时需要Source Data的问题。虽然是A+B式的，但确实有效。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203231559897.png"></p>
<h3 id="Beyond-Mutual-Information-Generative-Adversarial-Network-for-Domain-Adaptation-using-Information-Bottleneck-Constraint"><a href="#Beyond-Mutual-Information-Generative-Adversarial-Network-for-Domain-Adaptation-using-Information-Bottleneck-Constraint" class="headerlink" title="Beyond Mutual Information: Generative Adversarial Network for Domain Adaptation using Information Bottleneck Constraint"></a>Beyond Mutual Information: Generative Adversarial Network for Domain Adaptation using Information Bottleneck Constraint</h3><p>上线时间：2021-10-04<br>期刊：IEEE TMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9558836">https://ieeexplore.ieee.org/abstract/document/9558836</a></p>
<p>临床意义：临床迁移部署。通用的。<br>工程创新：A+B: DA + CAD（computer aided diagnosis）<br>方法：Information Bottleneck Constraint<br>开源：否</p>
<p>评论：对比实验做得一般，毕竟没有做UDA。是一个img2img的工作。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203231714268.png"></p>
<h3 id="Inconsistency-aware-Uncertainty-Estimation-for-Semi-supervised-Medical-Image-Segmentation"><a href="#Inconsistency-aware-Uncertainty-Estimation-for-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="Inconsistency-aware Uncertainty Estimation for Semi-supervised Medical Image Segmentation"></a>Inconsistency-aware Uncertainty Estimation for Semi-supervised Medical Image Segmentation</h3><p>上线时间：2021-10-04<br>期刊：IEEE TMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9558816">https://ieeexplore.ieee.org/abstract/document/9558816</a></p>
<p>临床意义：通用的标签稀缺，加上比较新的辅助诊断可用的uncertainty。<br>工程创新：A+B：Uncertainty Estimation + 半监督<br>方法：双重分割策略。复合网络。<br>开源：否</p>
<p>评论：uncertainty的使用和实现比较有趣。这个本身是有临床潜力的，可以让医生更注重那些可能有问题的病例。在分割时使用了保守分割策略（更侧重前景）和激进分割策略（更侧重背景的正确）。为达成这一目的，在代价设置上，让不同比例的前景、背景像素具备相同的代价。保守分割和激进分割两者相同为certain，两者不同为uncertian。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203231746920.png"></p>
<h3 id="Deep-Symmetric-Adaptation-Network-for-Cross-Modality-Medical-Image-Segmentation"><a href="#Deep-Symmetric-Adaptation-Network-for-Cross-Modality-Medical-Image-Segmentation" class="headerlink" title="Deep Symmetric Adaptation Network for Cross-Modality Medical Image Segmentation"></a>Deep Symmetric Adaptation Network for Cross-Modality Medical Image Segmentation</h3><p>上线时间：2021-08-16<br>期刊：IEEE TMI<br>链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9514499">https://ieeexplore.ieee.org/abstract/document/9514499</a></p>
<p>临床意义：通用的标签稀缺+部署困难。<br>工程创新：相互适应（？）<br>方法：复合网络。</p>
<p>开源：暂未开源： <a target="_blank" rel="noopener" href="https://github.com/ting2696/Deep-Symmetric-Adaptation-Network">https://github.com/ting2696/Deep-Symmetric-Adaptation-Network</a><br>评论：Symmetric Adaptation，让源域和目标域相互适应。图1挺有特点。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203281534187.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://whiteloran.github.io/2022/03/22/22032203/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="whiteloran">
      <meta itemprop="description" content="Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Whiteloran's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/22/22032203/" class="post-title-link" itemprop="url">论文略读2022-03-22</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-22 20:00:00" itemprop="dateCreated datePublished" datetime="2022-03-22T20:00:00+08:00">2022-03-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper/Daily-Skim/" itemprop="url" rel="index"><span itemprop="name">Daily Skim</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="A-Dual-Meta-Learning-Framework-based-on-Idle-Data-for-Enhancing-Segmentation-of-Pancreatic-Cancer"><a href="#A-Dual-Meta-Learning-Framework-based-on-Idle-Data-for-Enhancing-Segmentation-of-Pancreatic-Cancer" class="headerlink" title="A Dual Meta-Learning Framework based on Idle Data for Enhancing Segmentation of Pancreatic Cancer"></a>A Dual Meta-Learning Framework based on Idle Data for Enhancing Segmentation of Pancreatic Cancer</h3><p>上线时间：2022-03-19<br>期刊：MIA<br>链接：<a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.media.2021.102342">https://doi.org/10.1016/j.media.2021.102342</a></p>
<p>临床意义：小尺寸和不显眼的边界限制了胰腺癌的自动分割性能。由于图像采集和注释的困难，深度学习必须要在训练样本较少的情况下进行。为了缓解由小规模数据集引起的问题，作者从不同的研究中收集了闲置的胰腺癌多参数 MRI，以构建一个相对较大的数据集来增强 CT 胰腺癌分割。<br>工程创新：双重元学习框架的深度学习分割模型。<br>开源：否<br>评论：前置是一个多模态img2img的trans工作用来做数据增强，主要的分割模型是用了共享参数的（中间模态-CT模态）的元学习方法。对比实验做的很多都是baseline，在relate work时也没广泛的描述。结果不显著。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203222119342.png"></p>
<h3 id="Machine-learning-and-phone-data-can-improve-targeting-of-humanitarian-aid"><a href="#Machine-learning-and-phone-data-can-improve-targeting-of-humanitarian-aid" class="headerlink" title="Machine learning and phone data can improve targeting of humanitarian aid"></a>Machine learning and phone data can improve targeting of humanitarian aid</h3><p>上线时间：2022-03-16<br>期刊：Nature<br>链接：<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41586-022-04484-9">https://www.nature.com/articles/s41586-022-04484-9</a></p>
<p>意义：来自移动电话网络的数据可以提高人道主义援助的针对性。<br>方法：使用传统的调查数据来训练机器学习算法，以识别手机数据中的贫困模式；然后，经过训练的算法可以优先向最贫困的移动用户提供援助。<br>结果：突出了新数据源补充传统人道主义援助目标方法的潜力。<br>开源：<a target="_blank" rel="noopener" href="https://github.com/emilylaiken/togo-targeting-replication/">https://github.com/emilylaiken/togo-targeting-replication/</a></p>
<p>评论：机器学习的应用实例，实验规模大感觉确实是nature的先决条件啊。</p>
<h3 id="Instance-Importance-Aware-Graph-Convolutional-Network-for-3D-Medical-Diagnosis"><a href="#Instance-Importance-Aware-Graph-Convolutional-Network-for-3D-Medical-Diagnosis" class="headerlink" title="Instance Importance-Aware Graph Convolutional Network for 3D Medical Diagnosis"></a>Instance Importance-Aware Graph Convolutional Network for 3D Medical Diagnosis</h3><p>上线时间：2022-03-18<br>期刊：MIA<br>链接：<a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.media.2022.102421">https://doi.org/10.1016/j.media.2022.102421</a></p>
<p>临床意义：使用了患者标签，来做临床诊断。<br>方法：提出了一个实例重要性感知图卷积网络。用了multi-instance learning (MIL)。包括两方面，实例重要性和实例间感知。完成自动诊断任务。<br>开源：<a target="_blank" rel="noopener" href="https://github.com/CityU-AIM-Group/I2GCN">https://github.com/CityU-AIM-Group/I2GCN</a></p>
<p>方法对比：通过将每个 2D 切片转换为一个实例嵌入，许多工作将 3D 扫描的实例嵌入聚合为 bag embedding，然后进行 bag prediction 以实现对 3D 医疗数据的诊断。这些实例聚合方法无法感知和利用不同实例对诊断的重要性。通过随机删除节点的广泛使用的图增强与 MIL 框架冲突。通过丢弃关键实例（即病变切片），它可能会将 3D 感染扫描更改为负样本，并导致增强样本与其标签之间的不一致。因此，为 MIL 框架量身定制的基于图的增强策略有望实现准确的 3D 医学诊断。</p>
<p>评论：用了图网络确实会容易中期刊。使用了混合3D的MRI和CT图像（来自CC-CCII和PROSTATEx）来证明方法的通用性。一个图分类任务。</p>
<p><img data-src="https://raw.githubusercontent.com/whiteloran/PicBed/master/img/202203222137599.png"></p>
<h3 id="Multimodality-Imaging-to-Assess-Leaflet-Height-in-Mitral-Bioprosthetic-Valves-Implications-for-Mitral-Valve-in-Valve-Procedure"><a href="#Multimodality-Imaging-to-Assess-Leaflet-Height-in-Mitral-Bioprosthetic-Valves-Implications-for-Mitral-Valve-in-Valve-Procedure" class="headerlink" title="Multimodality Imaging to Assess Leaflet Height in Mitral Bioprosthetic Valves: Implications for Mitral Valve-in-Valve Procedure"></a>Multimodality Imaging to Assess Leaflet Height in Mitral Bioprosthetic Valves: Implications for Mitral Valve-in-Valve Procedure</h3><p>上线时间：2022-03-16<br>期刊：JACC:Imaging<br>链接：<a target="_blank" rel="noopener" href="https://www.jacc.org/doi/abs/10.1016/j.jcmg.2022.01.010">https://www.jacc.org/doi/abs/10.1016/j.jcmg.2022.01.010</a></p>
<p>评论：一个Imaging Vignette。讨论了多模态在二尖瓣修复手术的应用。包括了提取临床指标。可以作为多模态在困难病例上的广泛应用的实例。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="whiteloran"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">whiteloran</p>
  <div class="site-description" itemprop="description">Il n'ya qu'un héroïsme au monde, c'est de voir le monde tel qu'il est et de l'aimer.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/whiteloran" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;whiteloran" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-angle-double-up"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">whiteloran</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":300,"height":300},"mobile":{"show":false},"react":{"opacity":0.7},"log":false});</script></body>
</html>
